# predict.py
import os
import pickle
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏
from preprocess import clean_tweet, setup_nltk

MODEL_PATH = os.path.join('saved_models', 'best_model_glove.h5')
TOKENIZER_PATH = os.path.join('saved_models', 'tokenizer.pickle')
MAX_LEN = 50


def load_prediction_assets():
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    try:
        model = load_model(MODEL_PATH)

        with open(TOKENIZER_PATH, 'rb') as handle:
            tokenizer = pickle.load(handle)

        return model, tokenizer

    except FileNotFoundError:
        print("–û—à–∏–±–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –∏–ª–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print(f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ '{MODEL_PATH}' –∏ '{TOKENIZER_PATH}' —Å—É—â–µ—Å—Ç–≤—É—é—Ç.")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ main.py –¥–ª—è –∏—Ö —Å–æ–∑–¥–∞–Ω–∏—è.")
        return None, None
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
        return None, None


def predict_sentiment(text, model, tokenizer):
    cleaned_text = clean_tweet(text)

    sequence = tokenizer.texts_to_sequences([cleaned_text])

    padded_sequence = pad_sequences(sequence, maxlen=MAX_LEN,
                                    padding='post', truncating='post')

    prediction_prob = model.predict(padded_sequence)[0][0]

    if prediction_prob > 0.5:
        return "POSITIVE", prediction_prob
    else:
        return "NEGATIVE", prediction_prob


def main():
    setup_nltk()

    model, tokenizer = load_prediction_assets()

    if model is None or tokenizer is None:
        print("–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
        return

    print("=" * 50)
    print("–ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–≤–∏—Ç–æ–≤ –≥–æ—Ç–æ–≤–∞.")
    print("–í–≤–µ–¥–∏ 'exit' –∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
    print("=" * 50)

    while True:
        user_input = input("–í–≤–µ–¥–∏—Ç–µ —Ç–≤–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: ")

        if user_input.lower() in ['exit', 'quit']:
            break

        if not user_input.strip():
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.")
            continue

        label, probability = predict_sentiment(user_input, model, tokenizer)

        if label == "POSITIVE":
            print(f"   -> –†–ï–ó–£–õ–¨–¢–ê–¢: üü¢ –ü–û–ó–ò–¢–ò–í–ù–´–ô (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {probability * 100:.1f}%)")
        else:
            print(f"   -> –†–ï–ó–£–õ–¨–¢–ê–¢: üî¥ –ù–ï–ì–ê–¢–ò–í–ù–´–ô (–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {(1 - probability) * 100:.1f}%)")
        print("-" * 30)


if __name__ == '__main__':
    main()