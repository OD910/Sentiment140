
-----

# ОТЧЕТ

## 1\. Введение

### 1.1. Постановка задачи

Целью данной работы является разработка и программная реализация модели машинного обучения, предназначенной для автоматической классификации тональности (sentiment analysis) коротких текстовых сообщений на английском языке.
Задача сводится к бинарной классификации: определению принадлежности входного текста к одному из двух классов «позитивный» (Positive) или «негативный» (Negative).

### 1.2. Описание набора данных (Dataset)

В качестве исходных данных использован открытый набор данных **Sentiment140** (версия `training.1600000.processed.noemoticon.csv`).
Основные характеристики набора данных:

  * **Общий объем:** 1 600 000 записей.
  * **Источник данных:** Twitter API.
  * **Разметка целевой переменной:**
      * Класс `0`: Негативная окраска текста.
      * Класс `4`: Позитивная окраска текста.
  * **Особенности:** Данные представляют собой неструктурированный пользовательский текст, содержащий сленг, сокращения, орфографические ошибки и специальные символы. Эмотиконы (смайлики) были удалены на этапе предварительной обработки авторами датасета.

> Примечание: Несмотря на упоминание в документации класса `2` (нейтральный), анализ содержимого файла показал, что фактически в наборе данных присутствуют только полярные классы (0 и 4).

-----

## 2\. Предварительный анализ и обработка данных

### 2.1. Статистический анализ

Был проведен анализ распределения классов целевой переменной для оценки сбалансированности выборки.

  * **Количество объектов класса «Негативный» (0):** 800 000 (50%).
  * **Количество объектов класса «Позитивный» (4):** 800 000 (50%).

**Вывод:** Выборка является идеально сбалансированной. Применение методов балансировки классов (oversampling, undersampling или class weighting) не требуется.

### 2.2. Обоснование и методы нормализации данных

Сырые данные социальных сетей характеризуются высокой зашумленностью. Наличие неинформативных токенов увеличивает размерность векторного пространства без улучшения качества классификации.

Для повышения качества обучения был реализован следующий алгоритм нормализации текста:

1.  **Приведение к нижнему регистру:** Унификация написания слов.
2.  **Очистка от артефактов:** Удаление URL-адресов, упоминаний пользователей (`@username`), хэштегов, цифр и знаков препинания с помощью регулярных выражений.
3.  **Фильтрация стоп-слов:** Удаление служебных частей речи (артикли, предлоги), не несущих семантической нагрузки, с использованием библиотеки NLTK.
4.  **Лемматизация:** Приведение слов к их нормальной словарной форме (например, *«studied»* -> *«study»*) с использованием WordNetLemmatizer.

### 2.3. Векторизация

Для подачи данных в нейронную сеть была произведена токенизация и паддинг (padding):

  * **Размер словаря:** Ограничен 20 000 наиболее частотными лексемами.
  * **Длина вектора:** Зафиксирована на уровне 50 токенов (оптимальная длина для коротких сообщений Twitter).

-----

## 3\. Этапы разработки и оптимизации модели

Разработка велась итеративно, с постепенным усложнением архитектуры и методов обучения.

### Итерация №1: Базовая модель (Baseline)

**Цель:** Проверка работоспособности пайплайна (pipeline) обработки данных.
**Конфигурация:**

  * Обучающая выборка: сокращена до 200 000 записей.
  * Слой Embedding: обучение векторных представлений «с нуля» (случайная инициализация).
  * Архитектура: Embedding -> SpatialDropout1D -> Bidirectional GRU -> Dense.

**Результат:** Точность на валидации составила порядка **77.4%**. Наблюдалось быстрое переобучение модели.
**Вывод:** Модели недостаточно данных для формирования качественных семантических связей между словами «с нуля».

### Итерация №2: Применение Transfer Learning (GloVe 6B)

**Обоснование:** Для улучшения обобщающей способности было принято решение использовать предобученные векторные представления слов (Word Embeddings). Были использованы векторы **GloVe (6B tokens)**, обученные на корпусе Wikipedia.
**Реализация:**

  * Загрузка матрицы весов в слой Embedding.
  * Заморозка весов слоя (`trainable=False`).

**Результат:** Точность выросла до **78.5%**, однако наблюдался эффект недообучения (underfitting). Векторы, обученные на энциклопедических текстах, плохо интерпретировали неформальный язык социальных сетей.

### Итерация №3: Адаптация домена (Fine-Tuning)

**Обоснование:** Необходимо использование векторов, обученных на релевантном домене, и их тонкая настройка под конкретную задачу.
**Внесенные изменения:**

1.  Переход на векторы **GloVe Twitter 27B** (обучены на 2 млрд твитов).
2.  Разморозка слоя Embedding (`trainable=True`) для адаптации весов.
3.  Снижение скорости обучения (learning rate) оптимизатора Adam до `0.0005`.

Листинг 1. Фрагмент кода конфигурации слоя Embedding и компиляции модели:

```
# Использование матрицы GloVe Twitter
Embedding(input_dim=vocab_size, 
          output_dim=embedding_dim, 
          input_length=max_len,
          weights=[embedding_matrix], 
          trainable=True) # Разморозка для Fine-tuning

# Снижение Learning Rate
model.compile(loss='binary_crossentropy',
              optimizer=Adam(learning_rate=0.0005),
              metrics=['accuracy'])
```

**Результат:** Достигнута стабильная сходимость модели. Финальная точность на тестовой выборке составила **80.18%**.

-----

## 4\. Результаты и анализ эффективности

### 4.1. Количественные показатели

Оценка производилась на отложенной тестовой выборке объемом 320 000 записей (20% от общего объема).

| Метрика | Значение | Комментарий |
| :--- | :--- | :--- |
| **Accuracy** | **0.8018** | Доля правильных ответов |
| **Loss** | **0.4276** | Значение функции потерь (Binary Crossentropy) |

### 4.2. Качественный анализ

Архитектура модели (Bidirectional GRU) показала высокую эффективность в улавливании контекста.

  * Модель демонстрирует высокую уверенность (\>95%) на текстах с явно выраженной эмоциональной лексикой («hate», «love», «sad»).
  * В случаях отсутствия явных маркеров тональности модель принимает решение на основе косвенных признаков контекста, что является ожидаемым поведением.

-----

## 5\. Проблематика и решения

В ходе реализации проекта были решены следующие технические проблемы:

1.  **Кодировка входных данных:** Стандартный парсер Pandas не смог обработать CSV-файл в кодировке по умолчанию.
      * Решение: Явное указание кодировки `encoding="latin1"`.
2.  **Мониторинг обучения:** Необходимость визуального контроля за процессом обучения.
      * Решение: Реализован собственный класс `Callback`, выводящий примеры предсказаний на тестовых данных в конце каждой эпохи, а также подключен `TensorBoard`.
3.  **Вычислительная сложность:** Обучение на CPU вызывало ошибки нехватки памяти (OOM) и занимало значительное время.
      * Решение: Оптимизация размера пакета (`batch_size=1024`) и рекомендация использования GPU-ускорения.
4.  **Проблема инверсии смысла:** Удаление стоп-слов, таких как «not», в ряде случаев приводило к инверсии тональности (например, «not good» -> «good»).
      * Статус: Проблема локализована. В текущей реализации влияние на метрику признано допустимым, однако данный аспект выделен как основное направление для доработки.

-----

## 6\. Заключение

В результате выполнения работы спроектирована и реализована система анализа тональности на базе рекуррентной нейронной сети. Использование методов Transfer Learning (GloVe Twitter Embeddings) и тонкой настройки (Fine-tuning) позволило достичь точности **80.18%** на наборе данных Sentiment140.

**Перспективы развития (Future Work):**
Для дальнейшего повышения качества классификации (преодоления порога в 82-85%) предлагается:

1.  **Ансамблирование:** Объединение предсказаний текущей RNN-модели с моделью на базе сверточной сети (1D-CNN).
2.  **Изменение препроцессинга:** Исключение отрицаний (`not`, `no`) из списка удаляемых стоп-слов.
3.  **Применение Transformer-архитектур:** Переход на модели типа BERT/DistilBERT для более глубокого анализа семантического контекста.